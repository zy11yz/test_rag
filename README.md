# LLM RAG 演示应用

一个基于大语言模型(LLM)和检索增强生成(RAG)的简单演示应用。

## 功能特点

- 文档上传和处理
- 文档向量化和存储
- 基于用户问题的相关内容检索
- 利用LLM生成基于检索内容的回答

## 快速开始

1. 安装依赖

```bash
pip install -r requirements.txt
```

2. 配置环境变量

```bash
cp .env.example .env
```

然后编辑`.env`文件，填入你的OpenAI API密钥。

3. 启动应用

```bash
python run.py
```

或者直接执行：

```bash
./run.py
```

4. 打开浏览器访问 http://127.0.0.1:8000

## 使用说明

### 添加文档

1. 点击页面顶部的"文档上传"选项卡
2. 在文本框中粘贴或输入文档内容
3. 可选：为文档提供一个标题
4. 点击"上传文档"按钮

示例文档可以在`data/sample.txt`中找到，您可以复制其中的内容进行测试。

### 查询问答

1. 点击页面顶部的"问答"选项卡
2. 在输入框中输入您的问题
3. 选择要检索的文档数量
4. 点击"提交问题"按钮

### 示例问题

以下是一些您可以尝试的示例问题（在上传示例文档后）：

- 什么是人工智能？
- 机器学习有哪些主要类型？
- 解释一下什么是RAG技术及其优势

## API文档

您可以通过访问 http://127.0.0.1:8000/docs 查看完整的API文档。

## 项目结构

```
.
├── app                   # 主应用代码
│   ├── api               # API端点
│   ├── core              # 核心配置
│   ├── models            # 数据模型
│   ├── services          # 服务层(RAG、LLM集成)
│   ├── utils             # 工具函数
│   └── static            # 前端静态文件
├── data                  # 示例数据
└── tests                 # 测试代码
```

## 技术栈

- **后端**：FastAPI、LangChain
- **向量数据库**：ChromaDB
- **LLM接口**：OpenAI API
- **前端**：HTML、JavaScript、Bootstrap

